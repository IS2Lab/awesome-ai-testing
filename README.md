# Awesome-AI-Testing
A curated list of awesome publications and researchers on AI testing updated and maintained by [***The Intelligent System Security (IS2) Lab***](https://is2lab.github.io/).
![IS2Lab](https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/is2lab.png)

## AI Testing

***üëè What is AI Testing?*** 
AI Testing refers to the process of evaluating and verifying the performance of artificial intelligence (AI) systems. It involves testing the AI models, algorithms, and systems to ensure that they function correctly, produce accurate results, and are reliable in their decision-making processes.

***üëè How AI Testing worksÔºü*** AI Testing can be done in several ways, such as functional testing, performance testing, security testing, usability testing, and more. It also involves the creation of test cases and data sets, evaluating the accuracy of training data, validating models against real-world scenarios, and monitoring the performance of AI systems in production.

***üëè What is the goal of AI TestingÔºü*** The goal of AI testing is to identify and fix any errors, biases, or vulnerabilities in AI systems, ensuring that they meet the required standards and perform optimally in different environments. This is crucial for applications such as autonomous vehicles, medical diagnosis, and financial forecasting, where accuracy and reliability are essential.

## Contents
### [‚úÖ Researchers](./files/researchers.md)

<table rules="none" align="center">
	<tr>
		<td>
		<center>
                	<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/renkui.png" width="100" height="100">	
	               	<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=uuQA_rcAAAAJ"><b>Kui Ren</b> <br/> <i>ZJU, China</i></a>
            	</center>
        	</td>		
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/XinpengZhang%20.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=P76GtHwAAAAJ"><b>Xinpeng Zhang</b> <br/> <i>FDU, China</i></a>
            	</center>
		</td>		
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/xiaojiangDu.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=9K9BlyYAAAAJ"><b>Xiaojiang Du</b> <br/> <i>SIT, USA</i></a>
            	</center>
		</td>
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/CharlesClancy.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=OQPZELkAAAAJ"><b>Charles Clancy</b> <br/> <i>MITRE, USA</i></a>
            	</center>
		</td>
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/HaoChen.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=1Aa3qxIAAAAJ"><b>Hao Chen</b> <br/> <i>UC Davis, USA</i></a>
            	</center>
		</td>
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/HaojinZhu.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=_5lzNDUAAAAJ"><b>Haojin Zhu</b> <br/> <i>SJTU, China</i></a>
            	</center>
		</td>
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/zhuliehuang.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=6v_R6WgAAAAJ"><b>Liehuang Zhu</b> <br/> <i>BIT, China</i></a>
            	</center>
		</td>
	</tr>
</table>
<table rules="none" align="center">
	<tr>
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/weimingzhang.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=eTCfl6cAAAAJ"><b>Weiming Zhang</b> <br/> <i>USTC, China</i></a>
            	</center>
		</td>
		<td>
		<center>
    			<img src="https://github.com/IS2Lab/awesome-ai-testing/blob/main/picture/AlinaOprea.png" width="100" height="100">
			<br/>
			<a href="https://scholar.google.com/citations?hl=zh-CN&user=16J3izoAAAAJ&view_op=list_works&sortby=pubdate"><b>Alina Oprea</b> <br/> <i>NEU, USA</i></a>
            	</center>
		</td>
	</tr>
</table>



### [‚úÖ Conferences and Journals](./files/conferences.md)

- **Journals**
  * [**TDSC**](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8858) **|** [**TIFS**](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=10206) **|** [**TOSEM**](https://dl.acm.org/journal/tosem) **|** [**TSE**](http://dblp.uni-trier.de/db/journals/tse/)
- **Conferences**   
  * [**CCS**](https://css2022.xidian.edu.cn/) **|** [**S&P**](https://www.ieee-security.org/TC/SP2022/) **|** [**USENIX**](https://www.usenix.org/) **|**  [**NDSS**](https://www.ndss-symposium.org/) **|** [**ASE**](https://www.aseglobal.com/) **|** [**ICSE**](http://www.icse-conferences.org/) **|**  [**ISSTA**](https://dl.acm.org/conference/issta) **|** [**AAAI**](https://aaai.org/) **|** [**CVPR**](https://cvpr2022.thecvf.com/) **|** [**IJCAI**](https://ijcai-23.org/)
 
### [‚úÖ Papers](./files/papers.md)  ***‚ö†Ô∏è Only the latest work here, please click the title for more.***

#### [üå∏ Survey](./files/papers.md) 

###### [***IEEE Access 2023***] [*Toward Deep-Learning-Based Methods in Image Forgery Detection: A Survey*](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10035377)

###### [***ACM Computing Surveys 2023***] [*A Comprehensive Survey on Poisoning Attacks and Countermeasures in Machine Learning*](https://scholar.google.co.uk/scholar?q=A+Comprehensive+Survey+on+Poisoning+Attacks+and+Countermeasures+in+Machine+Learning.&hl=zh-CN&as_sdt=0&as_vis=1&oi=scholart)

###### [***Neurocomputing 2023***] [*Adversarial examples based on object detection tasks: A survey*](https://scholar.google.co.uk/scholar?hl=zh-CN&as_sdt=0%2C5&as_vis=1&q=Adversarial+examples+based+on+object+detection+tasks%3A+A+survey.&btnG=)

#### [üå∏ Evaluation of testing methods](./files/papers.md) 

###### [***CVPR 2022***] [*Is Neuron Coverage Needed to Make Person Detection More Robust?*](https://openaccess.thecvf.com/content/CVPR2022W/FaDE-TCV/papers/Pavlitskaya_Is_Neuron_Coverage_Needed_To_Make_Person_Detection_More_Robust_CVPRW_2022_paper.pdf)
    
###### [***ICSE 2021***] [*What Are We Really Testing in Mutation Testing for Machine Learning? A Critical Reflection.*](https://arxiv.org/abs/2103.01341)

#### [üå∏ Causality-Based Testing](./files/papers.md) 

###### [***ICSE 2022***] [*CARE: Causality-based Neural Network Repair*](https://arxiv.org/pdf/2204.09274.pdf)

###### [***ICML 2022***] [*Inducing Causal Structure for Interpretable Neural Networks.*](https://arxiv.org/abs/2112.00826)
    
#### [üå∏ Coverage-Guided Testing](./files/papers.md) 

###### [***CVPR  2022***] [*Is Neuron Coverage Needed to Make Person Detection More Robust?*](https://openaccess.thecvf.com/content/CVPR2022W/FaDE-TCV/papers/Pavlitskaya_Is_Neuron_Coverage_Needed_To_Make_Person_Detection_More_Robust_CVPRW_2022_paper.pdf)

###### [***NAACL 2022***] [*White-box Testing of NLP models with Mask Neuron Coverage.*](https://arxiv.org/abs/2205.05050)

###### [***SANER 2022***] [*Revisiting Neuron Coverage Metrics and Quality of Deep Neural Networks.*](https://arxiv.org/pdf/2201.00191.pdf)
    
#### [üå∏ Mutation Testing](./files/papers.md) 

###### [***ISSTA 2022***] [*BET: Black-Box Efficient Testing for Convolutional Neural Networks.*](https://dl.acm.org/doi/pdf/10.1145/3533767.3534386)

###### [***Information and Software Technology 2023***] [*A probabilistic framework for mutation testing in deep neural networks.*](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+probabilistic+framework+for+mutation+testing+in+deep+neural+networks.&btnG=)

###### [***Journal of Systems and Software 2023***] [*The language mutation problem: Leveraging language product lines for mutation testing of interpreters.*](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=The+language+mutation+problem%3A+Leveraging+language+product+lines+for+mutation+testing+of+interpreters.+&btnG=)

    
### [‚úÖ License](./LICENSE)

## Latest updates

### [***ISSTA '22***](https://dblp.org/db/conf/issta/issta2022.html) _ACM SIGSOFT International Symposium on Software Testing and Analysis_
### [***ICSE '22***](https://dblp.org/db/conf/icse/icse2022.html#DanilovaH0N22) _International Conference on Software Engineering_
### [***S&P '22***](https://dblp.org/db/conf/sp/sp2022.html) _IEEE Symposium on Security and Privacy_
### [***USENIX '22***](https://dblp.org/db/conf/uss/uss2022.html) _USENIX Security Symposium_
### [***CCS '22***](https://dblp.org/db/conf/ccs/ccs2022.html) _ACM SIGSAC Conference on Computer and Communications Security_
### [***NDSS '22***](https://dblp.org/db/conf/ndss/ndss2022.html) _Annual Network and Distributed System Security Symposium_
### [***ASE '22***](https://dblp.org/db/conf/kbse/ase2022.html) _IEEE/ACM International Conference on Automated Software Engineering_

## Latest achievements

### [ChatGPT](https://openai.com/blog/chatgpt/)
ChatGPT is a model which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response.
